{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"../04_survival_models/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core import Dataset, Workspace\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from uc2_functions import count_columns_by_dtype, validate_sksurv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to fine-tune a Cox model to enable the computation of survival metrics using the SSIGN features.\n",
    "We consider two variants:\n",
    "\n",
    "a. As in the paper https://pmc.ncbi.nlm.nih.gov/articles/PMC5536178/pdf/nihms790786.pdf\n",
    " – univariate Cox model on the SSIGN points\n",
    "\n",
    "b. Similarly as in our original manuscript with the GRANT model – multivariate Cox model on the categorized SSIGN variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DIR_SC = os.path.join(os.path.dirname(os.getcwd()), \"sc\")  # Legend\n",
    "DIR_MODEL_PKL = \"../models_pkl_review\"  # Weights for the models used during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "EXPERIMENT_NAME = \"UC2_review_ssign_finetune_2025_09_1\"\n",
    "PARENT_RUN_ID = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssign_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes the SSIGN score based on pre-processed features.\n",
    "\n",
    "    This function calculates the score for each component of the SSIGN score\n",
    "    (Pathological T, N, Metastasis, Tumor Size, Grade, Necrosis) and\n",
    "    sums them to get the total score.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing the necessary columns:\n",
    "            - 'IST_1_kidney1PathologicalStage2009' (numeric, mapped)\n",
    "            - 'IST_1_kidney1PN2009_1_0' (boolean, from one-hot encoding)\n",
    "            - 'IST_1_kidney1TumorDimension' (numeric, in cm)\n",
    "            - 'IST_1_kidney1Grading' (numeric, mapped)\n",
    "            - 'IST_1_kidney1Necrosis' (boolean)\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with added columns for each score component\n",
    "        and the total 'ssign_score'.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    df_scores = df.copy()\n",
    "\n",
    "    # 1. Pathological T category score\n",
    "    # pT1 (1.0, 2.0) -> 0; pT2 (3.0, 4.0) -> +1; pT3 (5.0, 6.0, 7.0) -> +2; pT4 (8.0) -> +4\n",
    "    pt_score_map = {1.0: 0, 2.0: 0, 3.0: 1, 4.0: 1, 5.0: 2, 6.0: 2, 7.0: 2, 8.0: 4}\n",
    "    df_scores[\"ssign_component_pT\"] = (\n",
    "        df_scores[\"IST_1_kidney1PathologicalStage2009\"].map(pt_score_map).fillna(0)\n",
    "    )\n",
    "\n",
    "    # 2. Regional lymph node status score\n",
    "    # pNx/pN0 -> 0; pN1/pN2 -> +2\n",
    "    # Based on your data, 'IST_1_kidney1PN2009_1_0' being True corresponds to pN1.\n",
    "    df_scores[\"ssign_component_pN\"] = np.where(\n",
    "        df_scores[\"IST_1_kidney1PN2009_1_0\"], 2, 0\n",
    "    )\n",
    "\n",
    "    # 3. Metastasis category score\n",
    "    # M0 -> 0; M1 -> +4. Per your inclusion criteria, all are M0.\n",
    "    df_scores[\"ssign_component_M\"] = 0\n",
    "\n",
    "    # 4. Tumor size score\n",
    "    # <5 cm -> 0; >=5 cm -> +2\n",
    "    df_scores[\"ssign_component_size\"] = np.where(\n",
    "        df_scores[\"IST_1_kidney1TumorDimension\"] >= 5, 2, 0\n",
    "    )\n",
    "\n",
    "    # 5. Tumor (nuclear) grade score\n",
    "    # Grade 1/2 -> 0; Grade 3 -> +1; Grade 4 -> +3\n",
    "    grade_score_map = {1.0: 0, 2.0: 0, 3.0: 1, 4.0: 3}\n",
    "    df_scores[\"ssign_component_grade\"] = (\n",
    "        df_scores[\"IST_1_kidney1Grading\"].map(grade_score_map).fillna(0)\n",
    "    )\n",
    "\n",
    "    # 6. Tumor necrosis present score\n",
    "    # No -> 0; Yes -> +2\n",
    "    df_scores[\"ssign_component_necrosis\"] = np.where(\n",
    "        df_scores[\"IST_1_kidney1Necrosis\"], 2, 0\n",
    "    )\n",
    "\n",
    "    # 7. Calculate the total SSIGN score\n",
    "    score_components = [\n",
    "        \"ssign_component_pT\",\n",
    "        \"ssign_component_pN\",\n",
    "        \"ssign_component_M\",\n",
    "        \"ssign_component_size\",\n",
    "        \"ssign_component_grade\",\n",
    "        \"ssign_component_necrosis\",\n",
    "    ]\n",
    "    df_scores[\"ssign_score\"] = df_scores[score_components].sum(axis=1)\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1693554728157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "\n",
    "subscription_id = \"753a0b42-95dc-4871-b53e-160ceb0e6bc1\"\n",
    "resource_group = \"rg-s-race-aml-dev-we\"\n",
    "workspace_name = \"amlsraceamldevwe01\"\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name=\"UC2_raw_survival_csm_ohe_5yrs\")\n",
    "df_ohe = dataset.to_pandas_dataframe()\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the schema from tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554728429
    }
   },
   "outputs": [],
   "source": [
    "tags = dataset.tags\n",
    "\n",
    "dtypes = json.loads(tags[\"dtypes_json\"])\n",
    "is_ordinal = json.loads(tags[\"is_ordinal_json\"])\n",
    "\n",
    "for col in dtypes.keys():\n",
    "    if dtypes[col] == \"category\":\n",
    "        categories = (\n",
    "            sorted(df_ohe[col].dropna().unique())\n",
    "            if is_ordinal[col]\n",
    "            else df_ohe[col].dropna().unique()\n",
    "        )\n",
    "        df_ohe[col] = pd.Categorical(\n",
    "            df_ohe[col], categories=categories, ordered=is_ordinal[col]\n",
    "        )\n",
    "    else:\n",
    "        df_ohe[col] = df_ohe[col].astype(dtypes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554728660
    }
   },
   "outputs": [],
   "source": [
    "count_columns_by_dtype(df_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start mlflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name=str(RANDOM_STATE))\n",
    "if PARENT_RUN_ID:\n",
    "    mlflow.set_tag(\"parent_run_id\", PARENT_RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop na on target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554729567
    }
   },
   "outputs": [],
   "source": [
    "not_features = [\"P_1_id\", \"death\", \"csm\", \"ocm\", \"ttdeath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554729802
    }
   },
   "outputs": [],
   "source": [
    "print(df_ohe.shape[0])\n",
    "df_ohe = df_ohe.dropna(subset=[\"ttdeath\", \"death\"])\n",
    "print(df_ohe.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554731698
    }
   },
   "outputs": [],
   "source": [
    "features_all = sorted(set(df_ohe.columns.tolist()) - set(not_features))\n",
    "print(len(features_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554731873
    }
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_ohe[features_all]\n",
    "y = np.array(\n",
    "    [(event, time) for event, time in zip(df_ohe[\"death\"], df_ohe[\"ttdeath\"])],\n",
    "    dtype=[(\"event\", bool), (\"time\", float)],\n",
    ")\n",
    "ids = df_ohe[\"P_1_id\"]\n",
    "mlflow.log_param(\n",
    "    \"death_perc_5yrs\",\n",
    "    pd.Series(y[\"event\"]).value_counts(sort=True, normalize=True)[True],\n",
    ")\n",
    "\n",
    "# Split data and IDs into training and testing sets\n",
    "(\n",
    "    X_train_missing,\n",
    "    X_test_missing,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    ids_train,\n",
    "    ids_test,\n",
    ") = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    ids,\n",
    "    test_size=0.2,\n",
    "    stratify=y[\"event\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "del X, y, ids\n",
    "# Check distributions of death event on train and test\n",
    "print(pd.Series(y_train[\"event\"]).value_counts(sort=True, normalize=True))\n",
    "print(pd.Series(y_test[\"event\"]).value_counts(sort=True, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and trasform on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_missing.copy()\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    max_iter=25, initial_strategy=\"median\", random_state=RANDOM_STATE\n",
    ")\n",
    "imputer = imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=X_train_missing.columns)\n",
    "\n",
    "# Assert\n",
    "assert set(X_train.columns) == set(X_train_missing.columns)\n",
    "\n",
    "del X_train_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_missing.copy()\n",
    "\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test_missing.columns)\n",
    "\n",
    "# Assert\n",
    "assert set(X_test.columns) == set(X_test_missing.columns)\n",
    "\n",
    "del X_test_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer rule-based SSIGN prognostic score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = calculate_ssign_score(X_train)\n",
    "X_test = calculate_ssign_score(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CoxPHSurvivalAnalysis_ssign_univariate_T1\"\n",
    "mlflow.start_run(run_name=model_name, nested=True)\n",
    "mlflow.log_param(\"random_state\", RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train univariate Cox model on the SSIGN points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "cox_ssign_univariate = CoxPHSurvivalAnalysis()\n",
    "cox_ssign_univariate.fit(X_train[[\"ssign_score\"]], y_train)\n",
    "mlflow.log_param(\"feature_names_in\", cox_ssign_univariate.feature_names_in_)\n",
    "mlflow.log_param(\"n_features_in\", cox_ssign_univariate.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights to pkl\n",
    "os.makedirs(DIR_MODEL_PKL, exist_ok=True)\n",
    "model_path = os.path.join(\n",
    "    DIR_MODEL_PKL, \"raw_{}_{}.pkl\".format(model_name, RANDOM_STATE)\n",
    ")\n",
    "joblib.dump(cox_ssign_univariate, model_path)\n",
    "mlflow.log_artifact(model_path)\n",
    "mlflow.log_param(\"model_path\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test set (internal validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_censored, result_ipcw, score_brier, mean_auc, fig = validate_sksurv_model(\n",
    "    model=cox_ssign_univariate,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test[[\"ssign_score\"]],\n",
    "    y_test=y_test,\n",
    "    tau=60,\n",
    ")\n",
    "print(\"concordance_index_censored\", round(result_censored, 3))\n",
    "mlflow.log_metric(\"concordance_index_censored\", result_censored)\n",
    "print(\"concordance_index_ipcw\", round(result_ipcw, 3))\n",
    "mlflow.log_metric(\"concordance_index_ipcw\", result_ipcw)\n",
    "print(\"integrated_brier_score\", round(score_brier, 3))\n",
    "mlflow.log_metric(\"integrated_brier_score\", score_brier)\n",
    "print(\"mean_cumulative_dynamic_auc\", round(mean_auc, 3))\n",
    "mlflow.log_metric(\"mean_cumulative_dynamic_auc\", mean_auc)\n",
    "mlflow.log_figure(fig, \"time_dependent_auc.png\")\n",
    "plt.show(fig)\n",
    "del model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CoxPHSurvivalAnalysis_ssign_finetune_T1\"\n",
    "mlflow.start_run(run_name=model_name, nested=True)\n",
    "mlflow.log_param(\"random_state\", RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ssign = [\n",
    "    \"ssign_component_pT\",\n",
    "    \"ssign_component_pN\",\n",
    "    # \"ssign_component_M\", # Always 0 on our cohort for inclusion criteria -> if used leads to singular matrix\n",
    "    \"ssign_component_size\",\n",
    "    \"ssign_component_grade\",\n",
    "    \"ssign_component_necrosis\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multivariate Cox model on the categorized SSIGN variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554732165
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "cox_ssign_finetune = CoxPHSurvivalAnalysis()\n",
    "cox_ssign_finetune.fit(X_train[features_ssign], y_train)\n",
    "mlflow.log_param(\"feature_names_in\", cox_ssign_finetune.feature_names_in_)\n",
    "mlflow.log_param(\"n_features_in\", cox_ssign_finetune.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights to pkl\n",
    "os.makedirs(DIR_MODEL_PKL, exist_ok=True)\n",
    "model_path = os.path.join(\n",
    "    DIR_MODEL_PKL, \"raw_{}_{}.pkl\".format(model_name, RANDOM_STATE)\n",
    ")\n",
    "joblib.dump(cox_ssign_finetune, model_path)\n",
    "mlflow.log_artifact(model_path)\n",
    "mlflow.log_param(\"model_path\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test set (internal validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_censored, result_ipcw, score_brier, mean_auc, fig = validate_sksurv_model(\n",
    "    model=cox_ssign_finetune,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test[features_ssign],\n",
    "    y_test=y_test,\n",
    "    tau=60,\n",
    ")\n",
    "print(\"concordance_index_censored\", round(result_censored, 3))\n",
    "mlflow.log_metric(\"concordance_index_censored\", result_censored)\n",
    "print(\"concordance_index_ipcw\", round(result_ipcw, 3))\n",
    "mlflow.log_metric(\"concordance_index_ipcw\", result_ipcw)\n",
    "print(\"integrated_brier_score\", round(score_brier, 3))\n",
    "mlflow.log_metric(\"integrated_brier_score\", score_brier)\n",
    "print(\"mean_cumulative_dynamic_auc\", round(mean_auc, 3))\n",
    "mlflow.log_metric(\"mean_cumulative_dynamic_auc\", mean_auc)\n",
    "mlflow.log_figure(fig, \"time_dependent_auc.png\")\n",
    "plt.show(fig)\n",
    "del model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End mlflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernel_info": {
   "name": "uc2"
  },
  "kernelspec": {
   "display_name": "uc2_pat",
   "language": "python",
   "name": "uc2_pat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
