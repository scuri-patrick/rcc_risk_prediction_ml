{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"../04_survival_models/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import kaplanmeier as km\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core import Dataset, Workspace\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    ParameterGrid,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sksurv.functions import StepFunction\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from uc2_functions import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554723785
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to fine-tune a Cox model using GRANT features as the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend\n",
    "PATH_LEGEND = \"Legenda_Variabili_Uri_Larcher.xlsx\"\n",
    "# Directories\n",
    "DIR_SC = os.path.join(os.path.dirname(os.getcwd()), \"sc\")  # Legend\n",
    "DIR_MODEL_PKL = \"../models_pkl\"  # Weights for the models used during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "EXPERIMENT_NAME = \"UC2_raw_survival_grant_finetune_2024_05\"\n",
    "PARENT_RUN_ID = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1693554728157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "\n",
    "subscription_id = \"753a0b42-95dc-4871-b53e-160ceb0e6bc1\"\n",
    "resource_group = \"rg-s-race-aml-dev-we\"\n",
    "workspace_name = \"amlsraceamldevwe01\"\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name=\"UC2_raw_survival_csm_ohe_5yrs\")\n",
    "df_ohe = dataset.to_pandas_dataframe()\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the schema from tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554728429
    }
   },
   "outputs": [],
   "source": [
    "tags = dataset.tags\n",
    "\n",
    "dtypes = json.loads(tags[\"dtypes_json\"])\n",
    "is_ordinal = json.loads(tags[\"is_ordinal_json\"])\n",
    "\n",
    "for col in dtypes.keys():\n",
    "    if dtypes[col] == \"category\":\n",
    "        categories = (\n",
    "            sorted(df_ohe[col].dropna().unique())\n",
    "            if is_ordinal[col]\n",
    "            else df_ohe[col].dropna().unique()\n",
    "        )\n",
    "        df_ohe[col] = pd.Categorical(\n",
    "            df_ohe[col], categories=categories, ordered=is_ordinal[col]\n",
    "        )\n",
    "    else:\n",
    "        df_ohe[col] = df_ohe[col].astype(dtypes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554728660
    }
   },
   "outputs": [],
   "source": [
    "count_columns_by_dtype(df_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.xlsx` Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554728980
    }
   },
   "outputs": [],
   "source": [
    "df_legend = pd.read_excel(\n",
    "    os.path.join(DIR_SC, PATH_LEGEND), sheet_name=\"Variabili Etichette DBURI\"\n",
    ")\n",
    "df_legend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554729363
    }
   },
   "outputs": [],
   "source": [
    "dict_legend = pd.Series(\n",
    "    df_legend[\"Etichetta\"].values, index=df_legend[\"Variabile\"]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start mlflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name=str(RANDOM_STATE))\n",
    "if PARENT_RUN_ID:\n",
    "    mlflow.set_tag(\"parent_run_id\", PARENT_RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop na on target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554729567
    }
   },
   "outputs": [],
   "source": [
    "not_features = [\"P_1_id\", \"death\", \"csm\", \"ocm\", \"ttdeath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554729802
    }
   },
   "outputs": [],
   "source": [
    "print(df_ohe.shape[0])\n",
    "df_ohe = df_ohe.dropna(subset=[\"ttdeath\", \"death\"])\n",
    "print(df_ohe.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554731698
    }
   },
   "outputs": [],
   "source": [
    "features_all = sorted(set(df_ohe.columns.tolist()) - set(not_features))\n",
    "print(len(features_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554731873
    }
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_ohe[features_all]\n",
    "y = np.array(\n",
    "    [(event, time) for event, time in zip(df_ohe[\"death\"], df_ohe[\"ttdeath\"])],\n",
    "    dtype=[(\"event\", bool), (\"time\", float)],\n",
    ")\n",
    "ids = df_ohe[\"P_1_id\"]\n",
    "mlflow.log_param(\n",
    "    \"death_perc_5yrs\",\n",
    "    pd.Series(y[\"event\"]).value_counts(sort=True, normalize=True)[True],\n",
    ")\n",
    "\n",
    "# Split data and IDs into training and testing sets\n",
    "(\n",
    "    X_train_missing,\n",
    "    X_test_missing,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    ids_train,\n",
    "    ids_test,\n",
    ") = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    ids,\n",
    "    test_size=0.2,\n",
    "    stratify=y[\"event\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "del X, y, ids\n",
    "# Check distributions of death event on train and test\n",
    "print(pd.Series(y_train[\"event\"]).value_counts(sort=True, normalize=True))\n",
    "print(pd.Series(y_test[\"event\"]).value_counts(sort=True, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and trasform on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_missing.copy()\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    max_iter=25, initial_strategy=\"median\", random_state=RANDOM_STATE\n",
    ")\n",
    "imputer = imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=X_train_missing.columns)\n",
    "\n",
    "# Assert\n",
    "assert set(X_train.columns) == set(X_train_missing.columns)\n",
    "\n",
    "del X_train_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_missing.copy()\n",
    "\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test_missing.columns)\n",
    "\n",
    "# Assert\n",
    "assert set(X_test.columns) == set(X_test_missing.columns)\n",
    "\n",
    "del X_test_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cox model - GRANT fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CoxPHSurvivalAnalysis_grant_finetune_T1\"\n",
    "mlflow.start_run(run_name=model_name, nested=True)\n",
    "mlflow.log_param(\"random_state\", RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As baseline we train a Cox model trained on features from prognostic model GRANT (Table 6.3 at https://uroweb.org/guidelines/renal-cell-carcinoma/chapter/prognostic-factors):\n",
    "\n",
    "1. Age > 60 years\n",
    "\n",
    "2. T classification = T3b, pT3c or pT4\n",
    "\n",
    "3. N classification = pN1\n",
    "\n",
    "4. (Fuhrman) grade = G3 or G4\n",
    "\n",
    "\n",
    "\n",
    "0-1 factors: favourable-risk disease\n",
    "\n",
    "2 or more factors: unfavourable-risk disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out mappings from preprocessing:\n",
    "\n",
    "Used for `IST_1_kidney1PathologicalStage2009`:\n",
    "```\n",
    "mapping_t_8lev = {\n",
    "    \"T1a\": 1.0,\n",
    "    \"T1b\": 2.0,\n",
    "    \"T2a\": 3.0,\n",
    "    \"T2b\": 4.0,\n",
    "    \"T3a\": 5.0,\n",
    "    \"T3b\": 6.0,\n",
    "    \"T3c\": 7.0,\n",
    "    \"T4\": 8.0,\n",
    "    \"Tx\": np.nan,\n",
    "}  # Rare event\n",
    "```\n",
    "\n",
    "Used for `IST_1_kidney1PN2009`:\n",
    "```\n",
    "mapping_n = {\n",
    "    \"No\": 0.0,\n",
    "    \"N1\": 1.0,\n",
    "    \"Nx\": 2.0,\n",
    "}  # Unsing np.nan would lead to more than 25% of nans\n",
    "```\n",
    "Already binary due to one-hot encoding\n",
    "\n",
    "Used for `IST_1_kidney1Grading`:\n",
    "```\n",
    "mapping_grade = {\"G1\": 1.0, \"G2\": 2.0, \"G3\": 3.0, \"G4\": 4.0}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binarize age\n",
    "X_train['ANM_1_age_binary'] = (X_train['ANM_1_age'] > 60).astype(\"boolean\")\n",
    "X_test['ANM_1_age_binary'] = (X_test['ANM_1_age'] > 60).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binarize pT\n",
    "X_train['IST_1_kidney1PathologicalStage2009_binary'] = (X_train['IST_1_kidney1PathologicalStage2009'] >= 6).astype(\"boolean\")\n",
    "X_test['IST_1_kidney1PathologicalStage2009_binary'] = (X_test['IST_1_kidney1PathologicalStage2009'] >= 6).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binarize grading\n",
    "X_train['IST_1_kidney1Grading_binary'] = (X_train['IST_1_kidney1Grading'] >= 3).astype(\"boolean\")\n",
    "X_test['IST_1_kidney1Grading_binary'] = (X_test['IST_1_kidney1Grading'] >= 3).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_grant = [\n",
    "    \"ANM_1_age_binary\",\n",
    "    \"IST_1_kidney1PathologicalStage2009_binary\",\n",
    "    \"IST_1_kidney1PN2009_1_0\",\n",
    "    \"IST_1_kidney1Grading_binary\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1693554732165
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "cox_grant = CoxPHSurvivalAnalysis()\n",
    "cox_grant.fit(X_train[features_grant], y_train)\n",
    "mlflow.log_param(\"feature_names_in\", cox_grant.feature_names_in_)\n",
    "mlflow.log_param(\"n_features_in\", cox_grant.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights to pkl\n",
    "os.makedirs(DIR_MODEL_PKL, exist_ok=True)\n",
    "model_path = os.path.join(DIR_MODEL_PKL, \"raw_{}_{}.pkl\".format(model_name, RANDOM_STATE))\n",
    "joblib.dump(cox_grant, model_path)\n",
    "mlflow.log_artifact(model_path)\n",
    "mlflow.log_param(\"model_path\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_censored, result_ipcw, score_brier, mean_auc, fig = validate_sksurv_model(model=cox_grant,\n",
    "                                                                                 y_train=y_train,\n",
    "                                                                                 X_test=X_test[features_grant],\n",
    "                                                                                 y_test=y_test,\n",
    "                                                                                 tau=60)\n",
    "print(\"concordance_index_censored\", round(result_censored, 3))\n",
    "mlflow.log_metric(\"concordance_index_censored\", result_censored)\n",
    "print(\"concordance_index_ipcw\", round(result_ipcw, 3))\n",
    "mlflow.log_metric(\"concordance_index_ipcw\", result_ipcw)\n",
    "print(\"integrated_brier_score\", round(score_brier, 3))\n",
    "mlflow.log_metric(\"integrated_brier_score\", score_brier)\n",
    "print(\"mean_cumulative_dynamic_auc\", round(mean_auc, 3))\n",
    "mlflow.log_metric(\"mean_cumulative_dynamic_auc\", mean_auc)\n",
    "mlflow.log_figure(fig, \"time_dependent_auc.png\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End mlflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernel_info": {
   "name": "uc2"
  },
  "kernelspec": {
   "display_name": "uc2_pat",
   "language": "python",
   "name": "uc2_pat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
